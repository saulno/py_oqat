{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  plot confusion matrices\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "from py_oqat.config_algorithms import ACOConfig\n",
    "from py_oqat.classifier import OQATClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def pretty_print_confusion_matrix(confusion_matrix):\n",
    "    for row in confusion_matrix:\n",
    "        print(row)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    # print(cm)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in classes],\n",
    "                  columns = [i for i in classes])\n",
    "    plt.figure(figsize = (7,5))\n",
    "    sns.heatmap(df_cm, annot=True, cmap=cmap)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n",
      "(71, 13)\n",
      "(71,)\n",
      "(107, 13)\n",
      "(107,)\n",
      "Distribution of training data\n",
      "1    28\n",
      "0    23\n",
      "2    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load iris dataset from sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Define the feature type for each column (discrete or continuous)\n",
    "column_names = [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\", \"a9\", \"a10\", \"a11\", \"a12\", \"a13\"]\n",
    "column_types = [\"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\", \"num\"]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=SEED)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Training data distribution\n",
    "print(\"Distribution of training data\")\n",
    "print(pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for class 1 created\n",
      "Score: 0.9545454545454546\n",
      "Model 1, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9090909090909091\n",
      "Model 2, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9090909090909091\n",
      "Model 3, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9545454545454546\n",
      "Model 4, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9545454545454546\n",
      "Model 5, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9545454545454546\n",
      "Model 6, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9545454545454546\n",
      "Model 7, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9090909090909091\n",
      "Model 8, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9090909090909091\n",
      "Model 9, number of clauses: 3\n",
      "Model for class 1 created\n",
      "Score: 0.9090909090909091\n",
      "Model 10, number of clauses: 3\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis: the most concise models classify better\n",
    "# We can meassure ow concise a model is by counting the number of cliques (disjunctive clauses)\n",
    "\n",
    "n_experiments = 10\n",
    "classifiers = []\n",
    "n_cycles = [2*i for i in range(1, 11)]\n",
    "n_ants = [2*i for i in range(1, 11)]\n",
    "for i in range(10):\n",
    "    aco_config = ACOConfig(algorithm=\"vertex-ac\", cycles=n_cycles[i], ants=n_ants[i], alpha=1, rho=0.99, tau_max=6., tau_min=0.01)\n",
    "    classifier = OQATClassifier(collision_strategy=\"best_score\", null_strategy=\"weighted\", heuristic=\"aco\", heuristic_config=aco_config)\n",
    "    classifier.fit(X_train, y_train, column_names, column_types, n_discrete_bins=3, learn_classes=[1])\n",
    "    classifiers.append(classifier)\n",
    "    print(f\"Model {i + 1}, number of clauses: {len(classifier.model[1]['cnf_weights'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
