{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config_algorithms import ACOConfig\n",
    "from oqat import OQATClassifier, OQATModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_confusion_matrix(confusion_matrix):\n",
    "    for row in confusion_matrix:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file and load it into a numpy array\n",
    "# df = pd.read_csv('datasets/test2.csv')\n",
    "df = pd.read_csv('datasets/hayes_roth.csv')\n",
    "\n",
    "# Separate features and labels into two dataframes\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Define the feature type for each column (discrete or continuous)\n",
    "column_names = X.columns.to_list()\n",
    "column_types = ['cat', 'cat', 'cat']\n",
    "\n",
    "# transform the dataframes into a numpy array\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the string labels into integers\n",
    "X = preprocessing.OrdinalEncoder().fit_transform(X)\n",
    "y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the training set\n",
    "\n",
    "# print(\"Before SMOTE\")\n",
    "# print(pd.Series(y_train).value_counts())\n",
    "# smote = SMOTE()\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "# print(\"After SMOTE\")\n",
    "# print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[21  5  0]\n",
      "[ 4 19  0]\n",
      "[ 2  1 14]\n",
      "Score:  0.8181818181818182\n",
      "|--- feature_3 <= 2.50\n",
      "|   |--- feature_2 <= 2.50\n",
      "|   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |--- feature_1 <= 0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_1 >  0.50\n",
      "|   |   |   |   |--- feature_3 <= 0.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_3 >  0.50\n",
      "|   |   |   |   |   |--- feature_3 <= 1.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_3 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_0 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_2 >  0.50\n",
      "|   |   |   |--- feature_1 <= 2.50\n",
      "|   |   |   |   |--- feature_1 <= 0.50\n",
      "|   |   |   |   |   |--- feature_3 <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_3 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_2 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_2 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_1 >  0.50\n",
      "|   |   |   |   |   |--- feature_1 <= 1.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_1 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_2 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_2 >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_1 >  2.50\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |--- feature_2 >  2.50\n",
      "|   |   |--- class: 2\n",
      "|--- feature_3 >  2.50\n",
      "|   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a classification tree algorithm from sklearn\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(\"Decision Tree\")\n",
    "pretty_print_confusion_matrix(cf)\n",
    "print(\"Score: \", tree_model.score(X_test, y_test))\n",
    "text_repr = tree.export_text(tree_model)\n",
    "print(text_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for class 0 created\n",
      "Model for class 1 created\n",
      "Model for class 2 created\n",
      "{0: (([age=0.0] ∨ [age=2.0] ∨ [education=0.0]) ∧ ([age=0.0] ∨ [education=2.0] ∨ [marital=0.0] ∨ [marital=2.0]) ∧ ([hobby=2.0] ∨ [hobby=0.0] ∨ [age=1.0] ∨ [education=0.0] ∨ [marital=0.0]) ∧ ([hobby=0.0] ∨ [age=0.0] ∨ [age=1.0] ∨ [education=2.0] ∨ [education=0.0] ∨ [marital=2.0] ∨ [marital=1.0]) ∧ ([hobby=0.0] ∨ [age=2.0] ∨ [age=1.0] ∨ [education=2.0] ∨ [education=1.0] ∨ [marital=2.0] ∨ [marital=1.0]) ∧ ([hobby=1.0] ∨ [hobby=2.0] ∨ [age=2.0] ∨ [age=0.0] ∨ [education=1.0] ∨ [education=2.0] ∨ [marital=1.0] ∨ [marital=0.0]) ∧ ([hobby=2.0] ∨ [hobby=1.0] ∨ [age=1.0] ∨ [age=2.0] ∨ [education=1.0] ∨ [education=0.0] ∨ [marital=2.0] ∨ [marital=0.0]) ∧ ([hobby=0.0] ∨ [hobby=2.0] ∨ [age=0.0] ∨ [age=2.0] ∨ [education=1.0] ∨ [education=2.0] ∨ [marital=0.0] ∨ [marital=1.0]) ∧ ([hobby=1.0] ∨ [hobby=2.0] ∨ [age=1.0] ∨ [age=0.0] ∨ [education=2.0] ∨ [education=0.0] ∨ [marital=1.0] ∨ [marital=2.0]) ∧ ([hobby=1.0] ∨ [hobby=0.0] ∨ [age=1.0] ∨ [age=2.0] ∨ [education=0.0] ∨ [education=1.0] ∨ [marital=0.0] ∨ [marital=2.0])), 1: (([education=1.0] ∨ [marital=1.0] ∨ [marital=2.0]) ∧ ([hobby=1.0] ∨ [age=1.0] ∨ [age=2.0] ∨ [education=2.0]) ∧ ([hobby=0.0] ∨ [hobby=2.0] ∨ [age=1.0] ∨ [education=2.0] ∨ [education=1.0] ∨ [marital=0.0]) ∧ ([hobby=2.0] ∨ [age=0.0] ∨ [age=2.0] ∨ [education=2.0] ∨ [education=0.0] ∨ [marital=0.0] ∨ [marital=2.0]) ∧ ([hobby=0.0] ∨ [hobby=1.0] ∨ [age=2.0] ∨ [age=0.0] ∨ [education=2.0] ∨ [education=1.0] ∨ [marital=1.0] ∨ [marital=0.0]) ∧ ([hobby=0.0] ∨ [hobby=1.0] ∨ [age=2.0] ∨ [age=1.0] ∨ [education=0.0] ∨ [education=1.0] ∨ [marital=0.0] ∨ [marital=2.0]) ∧ ([hobby=2.0] ∨ [hobby=1.0] ∨ [age=1.0] ∨ [age=0.0] ∨ [education=0.0] ∨ [education=2.0] ∨ [marital=1.0] ∨ [marital=2.0]) ∧ ([hobby=2.0] ∨ [hobby=0.0] ∨ [age=0.0] ∨ [age=2.0] ∨ [education=2.0] ∨ [education=1.0] ∨ [marital=1.0] ∨ [marital=0.0]) ∧ ([hobby=1.0] ∨ [hobby=2.0] ∨ [age=1.0] ∨ [age=2.0] ∨ [education=1.0] ∨ [education=0.0] ∨ [marital=0.0] ∨ [marital=2.0]) ∧ ([hobby=2.0] ∨ [hobby=1.0] ∨ [age=1.0] ∨ [age=0.0] ∨ [education=0.0] ∨ [education=2.0] ∨ [marital=1.0] ∨ [marital=2.0]) ∧ ([hobby=0.0] ∨ [hobby=2.0] ∨ [age=2.0] ∨ [age=1.0] ∨ [education=0.0] ∨ [education=2.0] ∨ [marital=1.0] ∨ [marital=2.0])), 2: (([age=3.0] ∨ [education=3.0] ∨ [marital=3.0]))}\n",
      "[1, 1, -1, -1, 0, 1, 1, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 2, 1, 0, 0, 2, 2, 1, 2, 1, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, -1, 0, 1, 0, -1, 0, 1, 2, 0, 0, 1, 2, 2, 1]\n",
      "OQAT\n",
      "[18, 5, 0]\n",
      "[10, 12, 0]\n",
      "[1, 2, 14]\n",
      "Score:  0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "# # Run the OQAT algorithm\n",
    "aco_config = ACOConfig(algorithm=\"vertex-ac\", cycles=20, ants=10, alpha=1, rho=0.99, tau_max=6., tau_min=0.01)\n",
    "classifier = OQATClassifier(collision_strategy=\"random\", heuristic=\"aco\", heuristic_config=aco_config)\n",
    "classifier.fit(X_train, y_train, column_names, column_types)\n",
    "print(classifier.model)\n",
    "y_pred = classifier.predict(X_test, column_names)\n",
    "print(y_pred)\n",
    "cf = classifier.confusion_matrix(y_pred, y_test)\n",
    "print(\"OQAT\")\n",
    "pretty_print_confusion_matrix(cf)\n",
    "print(\"Score: \", classifier.score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3. 0. 2.]\n",
      " [2. 2. 3. 1.]\n",
      " [2. 1. 1. 3.]]\n",
      "[0 1 1]\n",
      "(([age=3.0] ∨ [education=3.0] ∨ [marital=3.0]))\n",
      "[True, False, False]\n",
      "[False, True, True]\n",
      "[True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# array tu numpy array\n",
    "y_pred_np = np.array(y_pred)\n",
    "y_pred_filtered = y_pred_np[y_test == 2]\n",
    "X_test_filtered = X_test[y_test == 2]\n",
    "\n",
    "y_pred_filtered_2 = y_pred_filtered[y_pred_filtered != 2]\n",
    "X_test_filtered_2 = X_test_filtered[y_pred_filtered != 2]\n",
    "\n",
    "print(X_test_filtered_2)\n",
    "print(y_pred_filtered_2)\n",
    "\n",
    "print(classifier.model[2])\n",
    "y_pred_new = classifier.model[0].predict(X_test_filtered_2, column_names)\n",
    "print(y_pred_new)\n",
    "y_pred_new = classifier.model[1].predict(X_test_filtered_2, column_names)\n",
    "print(y_pred_new)\n",
    "y_pred_new = classifier.model[2].predict(X_test_filtered_2, column_names)\n",
    "print(y_pred_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1}, {1}, set(), set(), {0}, {1}, {1}, {0}, {2}, {0}, {0}, {1}, {0}, {2}, {2}, {0}, {0}, {0}, {1}, {0, 2}, {1}, {0}, {0}, {2}, {2}, {1}, {0, 2}, {1}, {0}, {0}, {0}, {0, 2}, {2}, {1}, {2}, {0}, {1}, {0, 1}, {0}, {2}, {0}, {1}, {0}, {1}, {0, 2}, {0}, {0, 1}, {0}, {0}, {0}, {1}, {1}, set(), {0}, {1}, {0}, set(), {0}, {1, 2}, {2}, {0}, {0}, {1}, {2}, {2}, {1, 2}]\n"
     ]
    }
   ],
   "source": [
    "classifier.collision_strategy = None\n",
    "y_pred_2 = classifier.predict(X_test, column_names)\n",
    "print(y_pred_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a29e914712ef84135244ee77708a8fb0d7fa4d04605cc0d1983dcf6b847904f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
